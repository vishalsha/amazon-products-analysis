{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Amazonmeta Assignment Pyspark.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xi_HSmTLZ97R",
        "outputId": "1d8482ee-8009-4c5c-a18c-65ae028358b3"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://mirrors.estointernet.in/apache/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "import gzip\n",
        "import requests\n",
        "import io\n",
        "import pandas as pd\n",
        "findspark.init()\n",
        "print(findspark.find())\n",
        "\n",
        "\n",
        "inputFilePath = \"https://snap.stanford.edu/data/bigdata/amazon/amazon-meta.txt.gz\"\n",
        "response = requests.get(inputFilePath, stream=True)\n",
        "metaDataFile = response.content\n",
        "conversion = io.BytesIO(metaDataFile)\n",
        "file = gzip.open(conversion,'rt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/spark-3.1.1-bin-hadoop2.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p1L3FGNriOS",
        "outputId": "5302cf78-5526-489c-c10c-3e1c4ddaffcd"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import networkx\n",
        "!pip install snap-stanford networkx stemming\n",
        "from stemming.porter2 import stem"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Collecting snap-stanford\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/11/76c0bbe6dbd5004ea6ae2fcd748d5d6a17f65c506b894f2de13d36918d13/snap_stanford-6.0.0-cp37-cp37m-manylinux1_x86_64.whl (11.6MB)\n",
            "\u001b[K     |████████████████████████████████| 11.6MB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
            "Collecting stemming\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/eb/fd53fb51b83a4e3b8e98cfec2fa9e4b99401fce5177ec346e4a5c61df71e/stemming-1.0.1.tar.gz\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx) (4.4.2)\n",
            "Building wheels for collected packages: stemming\n",
            "  Building wheel for stemming (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stemming: filename=stemming-1.0.1-cp37-none-any.whl size=11139 sha256=e49405ed923c003758c3cb1f52f7a9d0bf0354488c115b3183f658382e28a878\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/05/2e/2ddeb64d4464b854b48323f9676528c17560da7d153db7b0e2\n",
            "Successfully built stemming\n",
            "Installing collected packages: snap-stanford, stemming\n",
            "Successfully installed snap-stanford-6.0.0 stemming-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_9M5JUKg5RR"
      },
      "source": [
        "import string\n",
        "import re\n",
        "amazonProducts = []\n",
        "(Id, ASIN, Title, Categories, Group, Copurchased, SalesRank, TotalReviews, AvgRating) = (\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\")\n",
        "#reading lines from the file and creating a products dictionary obj with asin as key and metadata as its value\n",
        "def geNormalizedText(categories):\n",
        "    categories = re.compile('[%s]' % re.escape(string.digits+string.punctuation)).sub(' ', categories)\n",
        "    categories = ' '.join(set(categories.split())-set(stopwords.words(\"english\")))\n",
        "    categories = ' '.join(stem(word) for word in categories.split())\n",
        "    return categories\n",
        "\n",
        "\n",
        "for line in file:\n",
        "    MetaData = {}\n",
        "    line = line.strip()\n",
        "    if line.startswith(\"Id\",0):\n",
        "        Id = line[3:].strip()\n",
        "    elif line.startswith(\"ASIN\",0):\n",
        "        ASIN = line[5:].strip()\n",
        "    elif line.startswith(\"title\",0):\n",
        "        Title = line[7:].strip()\n",
        "    elif line.startswith(\"group\",0):\n",
        "        Group = line[6:].strip()\n",
        "    elif line.startswith(\"salesrank\",0):\n",
        "        SalesRank = line[10:].strip()\n",
        "    elif line.startswith(\"reviews\"):\n",
        "        ls = line.split()\n",
        "        TotalReviews = ls[2].strip()\n",
        "        AvgRating = ls[7].strip()\n",
        "    elif(line.startswith(\"categories\")):\n",
        "        ls = line.split()\n",
        "        Categories = ' '.join((file.readline()).lower() for i in range(int(ls[1].strip())))\n",
        "        Categories = geNormalizedText(Categories)\n",
        "    elif line.startswith(\"similar\",0):\n",
        "        ls = line.split()\n",
        "        Copurchased = ' '.join([similar for similar in ls[2:]])        \n",
        "    elif len(line) == 0:\n",
        "      try:\n",
        "        MetaData = {}\n",
        "        if ASIN != \"\":\n",
        "          MetaData['Id'] = Id\n",
        "          MetaData['ASIN'] = ASIN\n",
        "          MetaData['Title'] = Title\n",
        "          MetaData['Group'] = Group\n",
        "          MetaData['SalesRank'] = SalesRank\n",
        "          MetaData['Categories'] = Categories\n",
        "          MetaData['Similar'] = Copurchased\n",
        "          MetaData['Reviews'] = int(TotalReviews)\n",
        "          MetaData['Ratings'] = float(AvgRating)\n",
        "        amazonProducts.append(MetaData)\n",
        "      except :\n",
        "        continue\n",
        "file.close()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP1nuIRu1RB1",
        "outputId": "eeac52b7-659b-45cc-9037-4d820df1947f"
      },
      "source": [
        "print(len(amazonProducts))\n",
        "print(type(amazonProducts))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "548552\n",
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "gVp_kbxBWzdn",
        "outputId": "36160013-bb37-47ea-e7ce-279a9594fba2"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(amazonProducts)\n",
        "df.dropna(inplace=True)\n",
        "df\n",
        "#df.Id.count() #548551"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ASIN</th>\n",
              "      <th>Title</th>\n",
              "      <th>Group</th>\n",
              "      <th>SalesRank</th>\n",
              "      <th>Categories</th>\n",
              "      <th>Similar</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Ratings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0827229534</td>\n",
              "      <td>Patterns of Preaching: A Sermon Sampler</td>\n",
              "      <td>Book</td>\n",
              "      <td>396585</td>\n",
              "      <td>spiritu book clergi preach sermon religion chr...</td>\n",
              "      <td>0804215715 156101074X 0687023955 0687074231 08...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0738700797</td>\n",
              "      <td>Candlemas: Feast of Flames</td>\n",
              "      <td>Book</td>\n",
              "      <td>168596</td>\n",
              "      <td>spiritu book earth religion wicca witchcraft b...</td>\n",
              "      <td>0738700827 1567184960 1567182836 0738700525 07...</td>\n",
              "      <td>12.0</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0486287785</td>\n",
              "      <td>World War II Allied Fighter Planes Trading Cards</td>\n",
              "      <td>Book</td>\n",
              "      <td>1270652</td>\n",
              "      <td>craft general book hobbi garden home subject</td>\n",
              "      <td></td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0842328327</td>\n",
              "      <td>Life Application Bible Commentary: 1 and 2 Tim...</td>\n",
              "      <td>Book</td>\n",
              "      <td>631289</td>\n",
              "      <td>commentari christian life religion live testam...</td>\n",
              "      <td>0842328130 0830818138 0842330313 0842328610 08...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>1577943082</td>\n",
              "      <td>Prayers That Avail Much for Business: Executive</td>\n",
              "      <td>Book</td>\n",
              "      <td>455160</td>\n",
              "      <td>spiritu christian devot book prayerbook worshi...</td>\n",
              "      <td>157794349X 0892749504 1577941829 0892749563 15...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>548547</th>\n",
              "      <td>548547</td>\n",
              "      <td>B000059TOC</td>\n",
              "      <td>The Drifter</td>\n",
              "      <td>DVD</td>\n",
              "      <td>0</td>\n",
              "      <td>genr featur delaney timothi today actor w amaz...</td>\n",
              "      <td>630366704X B0002ERXB8 B0001932ZU B0001VTPUE B0...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>548548</th>\n",
              "      <td>548548</td>\n",
              "      <td>B00006JBIX</td>\n",
              "      <td>The House Of Morecock</td>\n",
              "      <td>DVD</td>\n",
              "      <td>0</td>\n",
              "      <td>general genr featur titl specialti independ ho...</td>\n",
              "      <td>B0002HOE6C B0002I84JO B00004WZQN B00069CQ8E B0...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>548549</th>\n",
              "      <td>548549</td>\n",
              "      <td>0879736836</td>\n",
              "      <td>Catholic Bioethics and the Gift of Human Life</td>\n",
              "      <td>Book</td>\n",
              "      <td>0</td>\n",
              "      <td>general philosophi spiritu book social sociolo...</td>\n",
              "      <td>1931709920 188187110X 081890643X 1580510469 08...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>548550</th>\n",
              "      <td>548550</td>\n",
              "      <td>B00008DDST</td>\n",
              "      <td>1, 2, 3 Soleils: Taha, Khaled, Faudel</td>\n",
              "      <td>DVD</td>\n",
              "      <td>0</td>\n",
              "      <td>general music genr featur video today concert ...</td>\n",
              "      <td>B00012FWNC B0002UNQQI B00069FKLO B0000CNTHZ B0...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>548551</th>\n",
              "      <td>548551</td>\n",
              "      <td>B00005MHUG</td>\n",
              "      <td>That Travelin' Two-Beat/Sings the Great Countr...</td>\n",
              "      <td>Music</td>\n",
              "      <td>0</td>\n",
              "      <td>general music vocal broadway vocalist classic ...</td>\n",
              "      <td>B00008OETQ B00005O6KL B00006RY87 B0002OTI98 B0...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>548551 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Id        ASIN  ... Reviews Ratings\n",
              "1            1  0827229534  ...     2.0     5.0\n",
              "2            2  0738700797  ...    12.0     4.5\n",
              "3            3  0486287785  ...     1.0     5.0\n",
              "4            4  0842328327  ...     1.0     4.0\n",
              "5            5  1577943082  ...     0.0     0.0\n",
              "...        ...         ...  ...     ...     ...\n",
              "548547  548547  B000059TOC  ...     1.0     5.0\n",
              "548548  548548  B00006JBIX  ...     8.0     3.0\n",
              "548549  548549  0879736836  ...     1.0     4.0\n",
              "548550  548550  B00008DDST  ...     3.0     5.0\n",
              "548551  548551  B00005MHUG  ...     1.0     5.0\n",
              "\n",
              "[548551 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJSPtw2y_zM0",
        "outputId": "8b255151-a5e4-4ab0-9a85-7a05cbbd767e"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 548551 entries, 1 to 548551\n",
            "Data columns (total 9 columns):\n",
            " #   Column      Non-Null Count   Dtype  \n",
            "---  ------      --------------   -----  \n",
            " 0   Id          548551 non-null  object \n",
            " 1   ASIN        548551 non-null  object \n",
            " 2   Title       548551 non-null  object \n",
            " 3   Group       548551 non-null  object \n",
            " 4   SalesRank   548551 non-null  object \n",
            " 5   Categories  548551 non-null  object \n",
            " 6   Similar     548551 non-null  object \n",
            " 7   Reviews     548551 non-null  float64\n",
            " 8   Ratings     548551 non-null  float64\n",
            "dtypes: float64(2), object(7)\n",
            "memory usage: 41.9+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFAEIa98F90O",
        "outputId": "d0ed7260-efcf-4ca5-b269-acb7713f0de2"
      },
      "source": [
        "print(df.Group.unique())\n",
        "#Saving the metadatafile in different formats\n",
        "#https://neptune.ai/blog/google-colab-dealing-with-files\n",
        "df.to_json(\"amazonmetadata.json\")\n",
        "df.to_csv(\"amazonmetadata.csv\", index=False)\n",
        "\n",
        "#Saving/downloading the files\n",
        "#from google.colab import files\n",
        "#files.download(\"amazonmetadata.csv\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Book' 'Music' 'DVD' 'Video' 'Toy' 'Video Games' 'Software'\n",
            " 'Baby Product' 'CE' 'Sports']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpyPYOUT4lPs"
      },
      "source": [
        "Pyspark Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF7rm6YHI8n8"
      },
      "source": [
        "import pyspark\n",
        "from pyspark.rdd import RDD\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.sql import functions\n",
        "from pyspark.sql.functions import lit, desc, col, size, array_contains, isnan, udf, hour, array_min, array_max, countDistinct\n",
        "from pyspark.sql.types import *"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf6xf5Gk4vVJ"
      },
      "source": [
        "MAX_MEMORY = '5G'\n",
        "# Initialize a spark session.\n",
        "conf = pyspark.SparkConf().setMaster(\"local[*]\") \\\n",
        "        .set('spark.executor.heartbeatInterval', 10000) \\\n",
        "        .set('spark.network.timeout', 10000) \\\n",
        "        .set(\"spark.core.connection.ack.wait.timeout\", \"3600\") \\\n",
        "        .set(\"spark.executor.memory\", MAX_MEMORY) \\\n",
        "        .set(\"spark.driver.memory\", MAX_MEMORY)\n",
        "\n",
        "def init_spark():\n",
        "    spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .appName(\"Amazon Meta Explore\") \\\n",
        "        .config(conf=conf) \\\n",
        "        .getOrCreate()\n",
        "    return spark\n",
        "\n",
        "spark = init_spark()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocJ2Gzde-jt6",
        "outputId": "0bef6d74-36e2-45ea-f316-dc2395f721bd"
      },
      "source": [
        "#Querying to the datasource:\n",
        "#converting metadata list to rdd\n",
        "\n",
        "_schema = StructType([\n",
        "    StructField('Id', StringType(), True),\n",
        "    StructField('ASIN', StringType(), True),\n",
        "    StructField('Title', StringType(), True),\n",
        "    StructField('Group', StringType(), True),\n",
        "    StructField('SalesRank', StringType(), True),\n",
        "    StructField('Categories', StringType(), True),\n",
        "    StructField('Similar', StringType(), True),\n",
        "    StructField('Reviews', IntegerType(), True),\n",
        "    StructField('Ratings', FloatType(), True)\n",
        "])\n",
        "\n",
        "#rdd = spark.sparkContext.parallelize(amazonProducts)\n",
        "#Creating spark dataframe, with schema details\n",
        "df_spark = spark.createDataFrame(amazonProducts, schema=_schema)\n",
        "print(df_spark.schema)\n",
        "df_spark.take(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "StructType(List(StructField(Id,StringType,true),StructField(ASIN,StringType,true),StructField(Title,StringType,true),StructField(Group,StringType,true),StructField(SalesRank,StringType,true),StructField(Categories,StringType,true),StructField(Similar,StringType,true),StructField(Reviews,IntegerType,true),StructField(Ratings,FloatType,true)))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SThQLYlO7Pe",
        "outputId": "8e77dda6-722c-41b9-ed58-12b78dc9f9cb"
      },
      "source": [
        "df_1 = df_spark.filter((df_spark.ASIN !='None') & (functions.length(df_spark.Similar) > 0))\n",
        "#df_spark.filter(functions.col(\"Similar\").isNotNull())\n",
        "#df_spark.filter(df_spark.Similar.isNotNull())\n",
        "#df_spark.filter(df_spark[\"Similar\"].isNotNull())\n",
        "#df_spark.na.drop(subset=[\"Similar\"].isNotNull())\n",
        "#df_spark.dropna(subset=[\"Similar\"]).isNotNull())\n",
        "df_1.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+----------+--------------------+-----+---------+--------------------+--------------------+-------+-------+\n",
            "| Id|      ASIN|               Title|Group|SalesRank|          Categories|             Similar|Reviews|Ratings|\n",
            "+---+----------+--------------------+-----+---------+--------------------+--------------------+-------+-------+\n",
            "|  1|0827229534|Patterns of Preac...| Book|   396585|spiritu book cler...|0804215715 156101...|      2|    5.0|\n",
            "|  2|0738700797|Candlemas: Feast ...| Book|   168596|spiritu book eart...|0738700827 156718...|     12|    4.5|\n",
            "|  4|0842328327|Life Application ...| Book|   631289|commentari christ...|0842328130 083081...|      1|    4.0|\n",
            "|  5|1577943082|Prayers That Avai...| Book|   455160|spiritu christian...|157794349X 089274...|      0|    0.0|\n",
            "|  6|0486220125|How the Other Hal...| Book|   188784|sociolog photo ca...|0486401960 045228...|     17|    4.0|\n",
            "|  7|B00000AU3R|               Batik|Music|     5392|general music mod...|B00002616C B00002...|      3|    4.5|\n",
            "|  8|0231118597| Losing Matt Shepard| Book|   277409|general lesbian b...|B000067D0Y 037572...|     15|    4.5|\n",
            "| 10|0375709363|The Edward Said R...| Book|   220379|general book soci...|039474067X 067973...|      6|    4.0|\n",
            "| 11|0871318237|Resetting the Clo...| Book|   412962|general mind alte...|1591200695 006098...|      1|    5.0|\n",
            "| 12|1590770218|Fantastic Food wi...| Book|    24741|mind carbohydr co...|0871319640 039953...|     12|    4.5|\n",
            "| 15|1559362022|Wake Up and Smell...| Book|   518927|art author theate...|1559360968 155936...|      8|    4.0|\n",
            "| 16|0195110382|War at Sea: A Nav...| Book|   631564|naval general war...|1585741485 014024...|     10|    4.5|\n",
            "| 17|0849311012|Telecommunication...| Book|   570183|industri econom s...|0071410546 158053...|      3|    3.5|\n",
            "| 18|B000007R0T|         Sol to Soul|Music|   109301|general music sty...|B000059QC1 B00000...|     15|    5.0|\n",
            "| 19|078510870X|Ultimate Marvel T...| Book|   612475|comic book childr...|0785114572 078511...|      8|    3.5|\n",
            "| 20|3895780812|Computed Tomograp...| Book|   179448|general book medi...|0865778973 007134...|      1|    5.0|\n",
            "| 21|0790747324|    The Time Machine|  DVD|      795|warner special ge...|B00007JMD8 630535...|    140|    4.5|\n",
            "| 22|B00005NTSV|       Come What May|Music|    83369|general music voc...|B00000JCDS B00000...|      4|    4.5|\n",
            "| 25|0939165252|Jailed for Freedo...| Book|   326756|book govern elect...|059500055X B00026...|      2|    3.5|\n",
            "| 26|1590930509|      Chicken Little| Book|   242571|general stori fol...|0439078172 089919...|      1|    4.0|\n",
            "+---+----------+--------------------+-----+---------+--------------------+--------------------+-------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JXYgRcx6Y6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d274599-4ff3-4853-806a-c3dfcb91710e"
      },
      "source": [
        "#reading the graph data\n",
        "data = requests.get(\"https://snap.stanford.edu/data/amazon0601.txt.gz\",stream=True)\n",
        "fr = io.BytesIO(data.content)\n",
        "fr_1 = gzip.open(fr, 'rt')\n",
        "tbl = pd.read_table(fr_1, delimiter=None, sep='\\t', skiprows=3)\n",
        "print(tbl.head(5))\n",
        "tbl.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   # FromNodeId  ToNodeId\n",
            "0             0         1\n",
            "1             0         2\n",
            "2             0         3\n",
            "3             0         4\n",
            "4             0         5\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3387388 entries, 0 to 3387387\n",
            "Data columns (total 2 columns):\n",
            " #   Column        Dtype\n",
            "---  ------        -----\n",
            " 0   # FromNodeId  int64\n",
            " 1   ToNodeId      int64\n",
            "dtypes: int64(2)\n",
            "memory usage: 51.7 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1Z0misC9bGb"
      },
      "source": [
        "#Building TUNGraph - Undirected\n",
        "import snap\n",
        "graph = snap.TUNGraph.New()\n",
        "#getting the unique nodes, using set\n",
        "#Two Columns - # FromNodeId & ToNodeId\n",
        "nodes = set(tbl['# FromNodeId'].tolist()+tbl['ToNodeId'].tolist())\n",
        "for n in nodes:\n",
        "  graph.AddNode(n)\n",
        "#using iteration to load edges - pair of nodes\n",
        "#in method 'PUNGraph_AddEdge', argument 2 of type 'int'\n",
        "for i,data in tbl.iterrows():\n",
        "  graph.AddEdge(int(data['# FromNodeId']),int(data['ToNodeId']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21UDsYyughti"
      },
      "source": [
        "snap.PrintInfo(graph, \"amazon node info\", \"amazon_node_info.txt\", False)\n",
        "#downloading the file from colab\n",
        "from google.colab import files\n",
        "files.download(\"amazon_node_info.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9xz3664RC9u"
      },
      "source": [
        "Graph Info:\n",
        "\n",
        "amazon node info:\\\n",
        "  Nodes:                    403394 \\\n",
        "  Edges:                    2443408 \\\n",
        "  Zero Deg Nodes:           0 \\\n",
        "  Zero InDeg Nodes:         0 \\\n",
        "  Zero OutDeg Nodes:        0\\\n",
        "  NonZero In-Out Deg Nodes: 403394\\\n",
        "  Unique directed edges:    4886816\\\n",
        "  Unique undirected edges:  2443408\\\n",
        "  Self Edges:               0\\\n",
        "  BiDir Edges:              4886816\\\n",
        "  Closed triangles:         3986507\\\n",
        "  Open triangles:           60250166\\\n",
        "  Frac. of closed triads:   0.062060\\\n",
        "  Connected component size: 0.999926\\\n",
        "  Strong conn. comp. size:  0.999926\\\n",
        "  Approx. full diameter:    20\\\n",
        "  90% effective diameter:  7.589876\\"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRmuL_9XQwmZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}